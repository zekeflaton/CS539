{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GAjBvz0fbeWu"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pylab as plt\n",
        "from google.colab import drive\n",
        "import cv2 as cv\n",
        "from datetime import datetime\n",
        "import math\n",
        "from PIL import Image\n",
        "from sklearn.preprocessing import LabelEncoder\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uD9X36CSbl4c",
        "outputId": "9be2c00e-f4bf-475e-8f7b-22d27d96e644"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "train_dir = \"drive/MyDrive/CS 539/Term Project/fruits-360_dataset/fruits-360/Training\"\n",
        "test_dir = \"drive/MyDrive/CS 539/Term Project/fruits-360_dataset/fruits-360/Test\"\n",
        "project_dir = \"drive/MyDrive/CS 539/Term Project\"\n",
        "checkpoint_dir = \"drive/MyDrive/CS 539/Term Project/Checkpoints\"\n",
        "\n",
        "def join_path(list):\n",
        "  return \"/\".join(list)"
      ],
      "metadata": {
        "id": "5veoiQ8Lbu2-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the list of labels\n",
        "labels = [name for name in os.listdir(train_dir)]\n"
      ],
      "metadata": {
        "id": "va5jaA-scEjp"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create my train/test X/Y sets\n",
        "images_x  =  []       \n",
        "labels_y  =  [] \n",
        "\n",
        "for label in os.listdir(train_dir):\n",
        "  for filename in os.listdir(join_path([train_dir, label])):\n",
        "    # print(label, filename)\n",
        "    # print(join_path([train_dir, label, filename]))\n",
        "    img  =  cv.imread(join_path([train_dir, label, filename]))\n",
        "    img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
        "    img_arr = Image.fromarray(img)\n",
        "    images_x.append(np.array(img_arr))\n",
        "    labels_y.append(label)\n"
      ],
      "metadata": {
        "id": "QSoyhPSjgL7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(images_x))\n",
        "print(len(labels_y))"
      ],
      "metadata": {
        "id": "Ml1GIaUPq4M1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode the labels\n",
        "lb_encod  =  LabelEncoder()\n",
        "labels_y = pd.DataFrame(labels_y)\n",
        "labels_y = lb_encod.fit_transform(labels_y[0])"
      ],
      "metadata": {
        "id": "lwUTvVNKhUjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(labels_y))\n",
        "print(labels_y)"
      ],
      "metadata": {
        "id": "eQu07nxuqrJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Check an image\n",
        "figure = plt.figure(figsize = (8,8))\n",
        "ax = figure.add_subplot(121)\n",
        "ax.imshow(images_x[0])\n",
        "bx = figure.add_subplot(122)\n",
        "bx.imshow(images_x[60])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "4Y8NDYbxhNnR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Saving the image array and corresponding labels\n",
        "images_x = np.array(images_x)\n",
        "np.save(join_path([checkpoint_dir, \"images\"]),images_x)\n",
        "np.save(join_path([checkpoint_dir, \"labels\"]),labels_y)\n",
        "\n"
      ],
      "metadata": {
        "id": "FTzTvyBs2rfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading the images and labels that we have saved above\n",
        "images_x = np.load(join_path([checkpoint_dir, \"images.npy\"]),allow_pickle = True)\n",
        "labels_y = np.load(join_path([checkpoint_dir, \"labels.npy\"]),allow_pickle = True)\n",
        "\n",
        "# Shuffle the data\n",
        "img_shape  = np.arange(images_x.shape[0])\n",
        "np.random.shuffle(img_shape)\n",
        "image = images_x[img_shape]\n",
        "labels_y = labels_y[img_shape]\n"
      ],
      "metadata": {
        "id": "66EnbVqaDFJo"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the train and test data sets\n",
        "num_classes = len(np.unique(labels_y))\n",
        "len_data = len(images_x)\n",
        "x_train, x_test = images_x[(int)(0.1*len_data):],images_x[:(int)(0.1*len_data)]\n",
        "y_train,y_test = labels_y[(int)(0.1*len_data):],labels_y[:(int)(0.1*len_data)]\n",
        "\n",
        "import keras\n",
        "y_train = keras.utils.to_categorical(y_train,num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test,num_classes)\n"
      ],
      "metadata": {
        "id": "DAs8aDk2C-4t"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9xF6x9AgEAJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "in5YI-39IFz1"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jhMXjCVJIgO",
        "outputId": "23477590-db9d-4c8f-d7b2-7463a560f24f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60923, 100, 100, 3)\n",
            "(60923, 131)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# VGG16"
      ],
      "metadata": {
        "id": "HrAkXEr3uqPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import load_img\n",
        "from tensorflow.keras.utils import img_to_array\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.applications.vgg16 import decode_predictions\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.layers import Dense,Conv2D,MaxPooling2D,Dropout,Flatten,MaxPool2D\n",
        "from keras.optimizers import RMSprop,Adam\n",
        "from keras.layers import Activation, Convolution2D, Dropout, Conv2D,AveragePooling2D, BatchNormalization,Flatten,GlobalAveragePooling2D\n",
        "from keras import layers\n",
        "from keras.regularizers import l2\n",
        "from keras.callbacks import ModelCheckpoint,ReduceLROnPlateau\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n"
      ],
      "metadata": {
        "id": "_UjRvtb8uqSW"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = VGG16(\n",
        "    weights=\"imagenet\",\n",
        "    include_top=False,\n",
        "    input_shape=(100,100, 3)\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9w86_BGzuqU7",
        "outputId": "988ba757-5453-420e-9e0e-9cb4c75a62da"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# image = load_img(join_path([train_dir, \"Apple Braeburn\", \"0_100.jpg\"]))\n",
        "# image = img_to_array(image)\n",
        "# image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
        "# image = preprocess_input(image)\n",
        "# yhat = model.predict(image) \n",
        "# label = decode_predictions(yhat)\n",
        "# label = label[0][0]\n",
        "# print('%s (%.2f%%)' % (label[1], label[2]*100)) \n",
        "\n"
      ],
      "metadata": {
        "id": "YexdDO9vuqXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.trainable=False\n",
        "for layer in base_model.layers:\n",
        "  layer.trainable = False"
      ],
      "metadata": {
        "id": "fTlPYjs4uqZe"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "last_layer = base_model.get_layer(\"block5_pool\")\n",
        "last_output = last_layer.output\n",
        "x = Flatten()(last_output)\n",
        "x = Dense(512, activation='relu', name='FC_2')(x) \n",
        "x = BatchNormalization()(x) \n",
        "x = Dropout(0.5)(x) \n",
        "x = Dense(131, activation='softmax', name='softmax')(x) \n",
        "new_model = Model(inputs=base_model.input, outputs=x) \n",
        "new_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mSgXxqkuqb0",
        "outputId": "48838e94-ee0a-41d8-db15-2cdfb05d9a50"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 100, 100, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 100, 100, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 100, 100, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 50, 50, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 50, 50, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 50, 50, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 25, 25, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 25, 25, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 25, 25, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 25, 25, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 12, 12, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 12, 12, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 6, 6, 512)         0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 3, 3, 512)         0         \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 4608)              0         \n",
            "                                                                 \n",
            " FC_2 (Dense)                (None, 512)               2359808   \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 512)              2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " softmax (Dense)             (None, 131)               67203     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 17,143,747\n",
            "Trainable params: 2,428,035\n",
            "Non-trainable params: 14,715,712\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_model.compile(\n",
        "    Adam(learning_rate=0.0001),\n",
        "    loss='categorical_crossentropy',\n",
        "     metrics=['accuracy']\n",
        "     )\n",
        "# new_model.fit_generator(train_batches, steps_per_epoch=4,\n",
        "#  validation_data=valid_batches, validation_steps=2,\n",
        "#  epochs=20, verbose=2)\n",
        "history = new_model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    batch_size=128,\n",
        "    epochs=5,\n",
        "    verbose=1,\n",
        "    validation_split = 0.33,\n",
        "    callbacks=[EarlyStopping(monitor='val_accuracy', patience = 5, restore_best_weights = True)]\n",
        "    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPOn_7xAuqdy",
        "outputId": "9276cea3-a3b6-432f-ed10-c3b253bd0c9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "319/319 [==============================] - 5880s 18s/step - loss: 6.0240 - accuracy: 0.0081 - val_loss: 5.3287 - val_accuracy: 0.0072\n",
            "Epoch 2/5\n",
            "319/319 [==============================] - 5542s 17s/step - loss: 5.6235 - accuracy: 0.0099 - val_loss: 5.1828 - val_accuracy: 0.0080\n",
            "Epoch 3/5\n",
            "319/319 [==============================] - 5518s 17s/step - loss: 5.4563 - accuracy: 0.0118 - val_loss: 5.1123 - val_accuracy: 0.0074\n",
            "Epoch 4/5\n",
            "319/319 [==============================] - 5637s 18s/step - loss: 5.3212 - accuracy: 0.0151 - val_loss: 5.1033 - val_accuracy: 0.0095\n",
            "Epoch 5/5\n",
            "145/319 [============>.................] - ETA: 35:57 - loss: 5.2072 - accuracy: 0.0172"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Te1ClcqyuqgA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XmgWWJafuqiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "blRzVs0luqkX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EPOiIBdluqmt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# InceptionV3"
      ],
      "metadata": {
        "id": "So3zXyNluqpQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# read in libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend, models, layers, optimizers\n",
        "import numpy as np\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from IPython.display import display\n",
        "from PIL import Image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os, shutil\n",
        "from tensorflow.keras.models import Model\n",
        "# Load InceptionV3 library\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "# Always clear the backend before training a model\n",
        "backend.clear_session()\n",
        "# InceptionV3 model and use the weights from imagenet\n",
        "conv_base = InceptionV3(weights = 'imagenet', #Useing the inception_v3 CNN that was trained on ImageNet data.  \n",
        "                  include_top = False)\n",
        "conv_base.trainable=False"
      ],
      "metadata": {
        "id": "BFbd_yOGPyBc"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect the InceptionV3 output to the fully connected layers\n",
        "InceptionV3_model = conv_base.output\n",
        "pool = GlobalAveragePooling2D()(InceptionV3_model)\n",
        "dense_1 = layers.Dense(1024, activation = 'relu')(pool)\n",
        "dense_2 = layers.Dense(512, activation = 'relu')(dense_1)\n",
        "output = layers.Dense(131, activation = 'softmax')(dense_2)\n"
      ],
      "metadata": {
        "id": "sEK-NUsBPyEy"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an example of the Archictecture to plot on a graph\n",
        "model_example = models.Model(inputs=conv_base.input, outputs=output)\n",
        "# plot graph\n",
        "plot_model(model_example)"
      ],
      "metadata": {
        "id": "DzNZRe8YPyHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define/Create the model for training\n",
        "model_InceptionV3 = models.Model(inputs=conv_base.input, outputs=output)\n",
        "# Compile the model with categorical crossentropy for the loss function and SGD for the optimizer with the learning\n",
        "# rate at 1e-4 and momentum at 0.9\n",
        "model_InceptionV3.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
        "    metrics=['accuracy'],\n",
        "    )\n"
      ],
      "metadata": {
        "id": "RD36gv0fPyKc"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EX3iQwIIPyMg",
        "outputId": "337be051-c20c-49c9-943e-5dcd3817dfc3"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 172993822524904783\n",
            "xla_global_id: -1\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Execute the model with fit_generator within the while loop utilizing the discovered GPU\n",
        "import tensorflow as tf\n",
        "with tf.device(\"/device:CPU:0\"):\n",
        "  history = model_InceptionV3.fit(\n",
        "      x_train,\n",
        "      y_train,\n",
        "      batch_size=128,\n",
        "      epochs=5,\n",
        "      verbose=1,\n",
        "      validation_split = 0.33,\n",
        "      callbacks=[EarlyStopping(monitor='val_accuracy', patience = 5, restore_best_weights = True)]\n",
        "      )\n",
        "\n",
        "    # history = model_InceptionV3.fit_generator(\n",
        "    #     train_generator,\n",
        "    #     epochs=5,\n",
        "    #     validation_data=test_generator,\n",
        "    #     verbose = 1,\n",
        "    #     callbacks=[EarlyStopping(monitor='val_accuracy', patience = 5, restore_best_weights = True)])"
      ],
      "metadata": {
        "id": "v8_J6bA9PyOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6_P5j_JvPyRA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5mvNFblTPyS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5T_n1BL1PyVL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom hand-crafted from scratch"
      ],
      "metadata": {
        "id": "pGih1SXxPyXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Conv2D,MaxPooling2D,Dropout,Flatten,MaxPool2D\n",
        "from keras.optimizers import RMSprop,Adam\n",
        "from keras.layers import Activation, Convolution2D, Dropout, Conv2D,AveragePooling2D, BatchNormalization,Flatten,GlobalAveragePooling2D\n",
        "from keras import layers\n",
        "from keras.regularizers import l2\n",
        "from keras.callbacks import ModelCheckpoint,ReduceLROnPlateau\n",
        "\n",
        "l2_reg = 0.001\n",
        "opt = Adam(lr = 0.001)\n",
        "s\n",
        "#Defining the CNN Model\n",
        "cnn_model  =  Sequential()\n",
        "cnn_model.add(Conv2D(filters = 32, kernel_size = (2,2), input_shape = (100,100, 3), activation = 'relu',kernel_regularizer = l2(l2_reg)))\n",
        "cnn_model.add(MaxPool2D(pool_size = (2,2)))\n",
        "cnn_model.add(Conv2D(filters = 64, kernel_size = (2,2), activation = 'relu',kernel_regularizer = l2(l2_reg)))\n",
        "cnn_model.add(MaxPool2D(pool_size = (2,2)))\n",
        "cnn_model.add(Conv2D(filters = 128, kernel_size = (2,2), activation = 'relu',kernel_regularizer = l2(l2_reg)))\n",
        "cnn_model.add(MaxPool2D(pool_size = (2,2)))\n",
        "cnn_model.add(Dropout(0.1))\n",
        "\n",
        "cnn_model.add(Flatten())\n",
        "\n",
        "cnn_model.add(Dense(1048, activation = 'relu'))\n",
        "cnn_model.add(Dense(262, activation = 'relu'))\n",
        "cnn_model.add(Dense(131, activation = 'softmax'))\n",
        "\n",
        "#CNN Model Summary\n",
        "cnn_model.summary()\n"
      ],
      "metadata": {
        "id": "SesYQ8Cwu3dr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Compiling the model\n",
        "cnn_model.compile(loss = 'categorical_crossentropy', optimizer = opt, metrics = ['accuracy'])\n"
      ],
      "metadata": {
        "id": "0hlXoVDnu3f3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training the CNN Model\n",
        "weights_file = \"weights.hdf5\"\n",
        "checkpoint = ModelCheckpoint(join_path([checkpoint_dir, weights_file]), monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "history = cnn_model.fit(x_train,y_train,batch_size = 128,epochs = 110,verbose = 1,validation_split = 0.33)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "YvR9wrJDIJ1H",
        "outputId": "ee95561e-74bc-4d1b-c5b2-bce861c941a6"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/110\n",
            " 26/319 [=>............................] - ETA: 11:19 - loss: 67.8938 - accuracy: 0.0045"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-7d3029fc9a2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mweights_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"weights.hdf5\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_file\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'min'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m110\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.33\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2453\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2454\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2456\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1861\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    500\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    503\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Check the performance\n",
        "scores  =  cnn_model.evaluate(x_test, y_test, verbose = 1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])\n"
      ],
      "metadata": {
        "id": "PkF6EsbNIPI4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualize the performance\n",
        "figure = plt.figure(figsize = (10,5))\n",
        "ax = figure.add_subplot(121)\n",
        "ax.plot(history.history['accuracy'])\n",
        "ax.plot(history.history['val_accuracy'])\n",
        "ax.legend(['Training Accuracy','Val Accuracy'])\n",
        "bx = figure.add_subplot(122)\n",
        "bx.plot(history.history['loss'])\n",
        "bx.plot(history.history['val_loss'])\n",
        "bx.legend(['Training Loss','Val Loss'])"
      ],
      "metadata": {
        "id": "ZsmArhhbI-mR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test\n",
        "test_path  =  'gdrive/My Drive/Dataset/Fruit Images/test_zip/test'\n",
        "t_labels = []\n",
        "t_images = []\n",
        "for filename in os.listdir('gdrive/My Drive/Dataset/Fruit Images/test_zip/test'):\n",
        "    if filename.split('.')[1]  =  =  'jpg':\n",
        "        img  =  cv2.imread(os.path.join(test_path,filename))\n",
        "        arr = Image.fromarray(img,'RGB')\n",
        "        img_arr = arr.resize((50,50))\n",
        "        t_labels.append(filename.split('_')[0])\n",
        "        t_images.append(np.array(img_arr))\n",
        "\n",
        "test_images = np.array(test_images)\n",
        "np.save(\"test_image\",test_images)\n",
        "test_image = np.load(\"image.npy\",allow_pickle = True)\n",
        "\n",
        "pred = np.argmax(model.predict(test_image),axis = 1)\n",
        "prediction  =  la.inverse_transform(pred)\n",
        "\n",
        "test_image = np.expand_dims(test_image[25],axis = 0)\n",
        "pred_test = np.argmax(model.predict(test_image),axis = 1)\n",
        "prediction_test  =  la.inverse_transform(pred_test)\n",
        "\n",
        "print(prediction_test[0])\n",
        "plt.imshow(test_images[11])\n"
      ],
      "metadata": {
        "id": "qPSGVSbpJBus"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}